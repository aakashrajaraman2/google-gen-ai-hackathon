{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_key= os.getenv(\"CLAUDE_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths =[\n",
    "    \"docs/90ade7e39d5e481f9aeb772a19a30234.pdf\",\n",
    "    \"docs/English Health Handbook.pdf\",\n",
    "    \"docs/English Motor Handbook.pdf\",\n",
    "    \"docs/insurance_motor_car_motor_policy_booklet_241017_NMDMG10249_v3.pdf\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [PyPDFLoader(url).load() for url in paths]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=50\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "\n",
    "\n",
    "def lanceDBConnection(embed):\n",
    "    db = lancedb.connect(\"/tmp/lancedb\")\n",
    "    table = db.create_table(\n",
    "        \"crag_demo\",\n",
    "        data=[{\"vector\": embed.embed_query(\"Hello World\"), \"text\": \"Hello World\"}],\n",
    "        mode=\"overwrite\",\n",
    "    )\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import LanceDB\n",
    "\n",
    "table = lanceDBConnection(model)\n",
    "\n",
    "vectorstore = LanceDB.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=model,\n",
    "    connection=table,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "import langsmith\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    keys: Dict[str, any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve(state):#Node 1. will act as a tool\n",
    "    \"\"\"\n",
    "    Helper function for retrieving documents. \n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"*\" * 5, \" RETRIEVE \", \"*\" * 5)\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    \n",
    "    return {\"keys\": {\"documents\": documents, \"question\": question}}#return the same state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "#llm = ChatAnthropic(model_name=\"claude-3-5-sonnet-20240620\",api_key=claude_key, streaming=True, model_kwargs=dict(system='You must complete several tasks '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "import os \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"cred.json\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "vertexai.init(project=\"vision-forge-414908\", location=\"us-central1\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-001\",\n",
    "                             system_instruction=\"You will be given various tasks in the following prompts. Remember that you must be as elaborate and professional as possible. Understand the task carefully, then respond\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grade_documents(state):#node 2\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    documents = state_dict[\"documents\"]\n",
    "    \n",
    "    binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a policy document to a user question. \\n\n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document relates to the user question, grade it as relevant. \\n\n",
    "        Ensure that the user's question's specific policy question matches the policy type (auto, pet, life, etc) in the documents.\n",
    "        Only give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "        Only answer with the words 'yes' or 'no'. Do not provide any other text. \\n\\n\n",
    "        \"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm \n",
    "    print(\"here2\")\n",
    "\n",
    "    # Score\n",
    "    filtered_docs = []\n",
    "    search = \"No\"  # Default do not opt for web search to supplement retrieval\n",
    "    for d in documents:\n",
    "        score = chain.invoke({\"question\": question, \"context\": d.page_content})\n",
    "        score = [score.content.replace(\"\\n\", \"\")]\n",
    "        print(\"THIS IS THE SCORE:\", score)\n",
    "        grade2 = score[0]\n",
    "        if \"yes\" in grade2 or \"Yes\" in grade2:\n",
    "            print(\"*\" * 5, \" RATED DOCUMENT: RELEVANT\", \"*\" * 5)\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"*\" * 5, \" RATED DOCUMENT: NOT RELEVANT\", \"*\" * 5)\n",
    "            continue\n",
    "        \n",
    "        #if not even half the docs are relevant\n",
    "        if len(filtered_docs) < int(len(documents)/2):\n",
    "            search = \"Yes\"\n",
    "\n",
    "    return {\n",
    "        \"keys\": {\n",
    "            \"documents\": filtered_docs,\n",
    "            \"question\": question,\n",
    "            \"run_web_search\": search,\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):#node 3. also, end.\n",
    "    \"\"\"\n",
    "    Helper function for generating answers\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"*\" * 5, \" GENERATE \", \"*\" * 5)\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    documents = state_dict[\"documents\"]\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "    template='''\n",
    "    You are an assistant for insurance related question-answering tasks. \n",
    "    Use the following pieces of insurance policies context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Give as much information as possible. Use a professional tone, and elaborate as much as you can.\n",
    "\n",
    "    Question: {question} \n",
    "\n",
    "    Context: {context} \n",
    "\n",
    "    Answer:\n",
    "    ''',\n",
    "    input_variables=[\"question\", \"context\"],)\n",
    "\n",
    "    # LLM\n",
    "\n",
    "\n",
    "    # RAG Chain\n",
    "    rag_chain = prompt | llm \n",
    "\n",
    "    # Run generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\n",
    "        \"keys\": {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(state):#node 4\n",
    "    \"\"\"\n",
    "    Helper function for transforming the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"*\" * 5, \"TRANSFORM QUERY\", \"*\" * 5)\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    documents = state_dict[\"documents\"]\n",
    "\n",
    "    # Create a prompt template with format instructions and the query\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are generating questions that is well optimized for retrieval. \\n\n",
    "        Look at the input and try to reason about the underlying sematic intent / meaning. \\n\n",
    "        You have to modify the search query to only look for Indian related results. \n",
    "        Only return the question, no further explanation or text.\\n\n",
    "        Here is the initial question:\n",
    "        \\n --------- \\n\n",
    "        {question}\n",
    "        \\n --------- \\n\n",
    "        Formulate an improved question: \"\"\",\n",
    "        input_variables=[\"question\"],\n",
    "    )\n",
    "\n",
    "    model = llm\n",
    "\n",
    "    # Prompt\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "    better_question = chain.invoke({\"question\": question})\n",
    "    print(better_question)\n",
    "\n",
    "    return {\"keys\": {\"documents\": documents, \"question\": better_question}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):#node 5\n",
    "    \"\"\"\n",
    "    Helper function to determine whether to generate an answer or re-generate a question for web search.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state of the agent, including all keys.\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"*\" * 5, \" DECIDE TO GENERATE \", \"*\" * 5)\n",
    "    state_dict = state[\"keys\"]\n",
    "    search = state_dict[\"run_web_search\"]\n",
    "\n",
    "    if \"yes\" in search or \"Yes\" in search:\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\"*\" * 5, \" DECISION: TRANSFORM QUERY and RUN WEB SEARCH \", \"*\" * 5)\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"*\" * 5, \" DECISION: GENERATE \", \"*\" * 5)\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "\n",
    "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(state):#node 6\n",
    "    \"\"\"\n",
    "    Helper function to do Web search based on the re-phrased question using Tavily API.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"*\" * 5, \" WEB SEARCH \", \"*\" * 5)\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    documents = state_dict[\"documents\"]\n",
    "\n",
    "    tool = tavily_client.search(    query=question,\n",
    "                                    search_depth=\"advanced\",\n",
    "                                    include_answer=True,\n",
    "                                    include_domains=[\"https://www.acko.com/car-insurance/irdai-rules/\", \"https://www.lexisnexis.in/blogs/insurance-law-in-india/.\"])\n",
    "\n",
    "    docs = tool[\"answer\"]\n",
    "    #web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    #print(web_results)\n",
    "    web_results = Document(page_content=docs)\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\"keys\": {\"documents\": documents, \"question\": question}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)#inherit empty state\n",
    "\n",
    "# Define the nodes\n",
    "#nodes work by (node_name, function_of_node)\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve docs\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade retrieved docs\n",
    "workflow.add_node(\"generate\", generate)  # generate answers\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query for web search\n",
    "workflow.add_node(\"web_search\", web_search)  # web search\n",
    "\n",
    "# Build graph\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(#conditional edges are based on a condition, which is a function that returns a boolean value\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"web_search\")\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****  RETRIEVE  *****\n",
      "here2\n",
      "THIS IS THE SCORE: ['yes']\n",
      "*****  RATED DOCUMENT: RELEVANT *****\n",
      "THIS IS THE SCORE: ['no']\n",
      "*****  RATED DOCUMENT: NOT RELEVANT *****\n",
      "THIS IS THE SCORE: ['no ']\n",
      "*****  RATED DOCUMENT: NOT RELEVANT *****\n",
      "THIS IS THE SCORE: ['no ']\n",
      "*****  RATED DOCUMENT: NOT RELEVANT *****\n",
      "*****  DECIDE TO GENERATE  *****\n",
      "*****  DECISION: TRANSFORM QUERY and RUN WEB SEARCH  *****\n",
      "***** TRANSFORM QUERY *****\n",
      "What is the maximum length of stay allowed in Indian hospitals? \n",
      "\n",
      "*****  WEB SEARCH  *****\n",
      "*****  GENERATE  *****\n",
      "[Document(metadata={'vector': [0.005689900368452072, -0.0465342178940773, -0.0070617953315377235, -0.047312360256910324, -0.043002013117074966, 0.033535394817590714, 0.06498000770807266, 0.039269622415304184, 0.03488471359014511, -0.056162279099226, -0.005318034905940294, 0.06130072474479675, -0.009270560927689075, -0.021043384447693825, 0.025922106578946114, -0.05320592597126961, 0.05944201350212097, -0.0937216579914093, -0.019636210054159164, 0.07241089642047882, 0.05197257921099663, -0.006293134298175573, -0.007491679862141609, 0.04684695601463318, -0.05601641535758972, -0.06963860988616943, 0.018922941759228706, -0.003832191228866577, 0.04164235666394234, 0.00677380058914423, 0.04173356667160988, 0.05154023692011833, 0.10779991000890732, -0.04611261188983917, 0.050458259880542755, 0.01225365325808525, 0.006058461032807827, 0.01222214661538601, -0.023754175752401352, 0.012377958744764328, -0.0037521582562476397, -0.07087033241987228, 0.04886618256568909, -0.01023191399872303, 0.08239440619945526, -0.020556887611746788, -0.08745906502008438, -0.0035260121803730726, -0.01395678985863924, 0.06057267636060715, -0.004653243813663721, -0.015495236963033676, -0.027410268783569336, 0.06875769793987274, -0.026014303788542747, -0.04386496916413307, 0.003995776642113924, -0.09841848909854889, -0.061415817588567734, 0.03626498579978943, -0.02510821633040905, 0.04239252582192421, 0.04656953737139702, 0.04920892417430878, -0.042088840156793594, 0.016186853870749474, 0.04775896295905113, -0.062338557094335556, 0.03254302591085434, -0.05923435464501381, -0.01279959362000227, -0.07298143208026886, -0.022688617929816246, 0.10786090791225433, -0.034294966608285904, -0.03757833316922188, 0.01959885098040104, 0.03595718741416931, 0.02847553975880146, -0.01670270785689354, 0.015448668040335178, 0.014105640351772308, 0.029187319800257683, 0.007467986550182104, -0.0636352077126503, -0.04546536132693291, -0.03032050095498562, 0.012186502106487751, 0.012664551846683025, -0.00673002889379859, 0.06631410866975784, 0.00886195246130228, -0.079367995262146, -0.07498570531606674, 0.08883945643901825, -0.04456267133355141, -0.02553599886596203, -0.0930316224694252, 0.03977608680725098, 0.045193638652563095, -0.00941663607954979, -0.02999100089073181, 0.04372979700565338, 0.07107116281986237, -0.11224706470966339, -0.049977485090494156, -0.015894830226898193, -0.07119380682706833, -0.009721034206449986, -0.05592884123325348, 0.022104941308498383, 0.006491194944828749, 0.07347031682729721, -0.04511316865682602, -0.06125267967581749, 0.02659601904451847, -0.04090527445077896, 0.004332779441028833, 0.07561635226011276, -0.017879705876111984, 0.02309573069214821, 0.05970623344182968, -0.04356497898697853, -0.0512651652097702, -0.016619479283690453, 0.010708965361118317, 0.0065852440893650055, 4.375254258607865e-33, 0.10040615499019623, -0.021547749638557434, 0.022690314799547195, -0.023914646357297897, 0.03557204082608223, -0.013089640997350216, -0.04379643499851227, -0.05409441515803337, 0.02770213782787323, 0.04529157653450966, -0.0447048656642437, -0.01961030252277851, 0.049727074801921844, -0.08117601275444031, 0.046342238783836365, 0.06386826187372208, 0.05785788595676422, 0.0781978890299797, -0.0027632140554487705, 0.056905072182416916, 0.0030942102894186974, -0.028086785227060318, -0.03565632924437523, -0.003111388999968767, 0.015913892537355423, 0.06761448085308075, 0.05518751218914986, -0.01885651983320713, 0.025513269007205963, 0.006825805641710758, 0.02133847586810589, 0.01630004681646824, -0.028206465765833855, 0.0067047737538814545, 0.019942332059144974, -0.015597380697727203, -0.04165369272232056, -0.02258552797138691, -0.04016059264540672, -0.046468403190374374, -0.08356521278619766, -0.004424071870744228, -0.03372033312916756, 0.06310965865850449, 0.048620983958244324, -0.009088950231671333, 0.018004830926656723, -0.010787314735352993, -0.03212180733680725, 0.006837734952569008, -0.05759115144610405, -0.03369361162185669, -0.06256848573684692, -0.007158085238188505, 0.019606074318289757, 0.023355063050985336, 0.00743999145925045, 0.04226038232445717, 0.03650436922907829, 0.10233696550130844, 0.13248929381370544, 0.04059647396206856, -0.00673221331089735, -0.016257282346487045, -0.0027191895060241222, 0.016286494210362434, 0.01566430926322937, -0.0734502300620079, 0.09934376180171967, -0.032758548855781555, -0.020937053486704826, -0.00847596488893032, 0.03278953209519386, 0.020658833906054497, -0.0104135200381279, 0.005693052429705858, 0.02085449919104576, 0.010025921277701855, 0.016061564907431602, 0.013881372287869453, -0.06471816450357437, 0.05339495837688446, -0.023564999923110008, 0.03897741809487343, 0.05911925062537193, 0.012359334155917168, -0.00523826340213418, 0.03421344980597496, -0.11948597431182861, -0.09262590855360031, -0.0753406435251236, 0.017213162034749985, 0.038200072944164276, 0.1273168921470642, 0.013768809847533703, -6.1508708016195776e-33, 0.00615360401570797, 0.006686506327241659, -0.06400055438280106, -0.04455779865384102, -0.029620269313454628, -0.008093329146504402, 0.009208171628415585, -0.056381527334451675, 0.03940829634666443, 0.0030993353575468063, -0.09447875618934631, -0.046954527497291565, -0.0048944950103759766, -0.0355728454887867, 0.0016982994275167584, -0.011017103679478168, -0.002719678683206439, -0.09807457774877548, -0.12196613103151321, 0.10213541984558105, 0.03135518357157707, 0.08740300685167313, 0.04296136274933815, 0.013569873757660389, 0.0003388195764273405, 0.047104839235544205, 0.0031348164193332195, 0.10792277753353119, -0.019147291779518127, -0.09732671082019806, -0.04818161576986313, -0.09967481344938278, -0.08577549457550049, -0.041757091879844666, -0.05602126568555832, -0.042067620903253555, 0.056738413870334625, -0.026589440181851387, -0.05056513100862503, 0.03188033029437065, 0.05332648381590843, -0.03712411969900131, 0.004613426513969898, 0.09213927388191223, -0.01483294740319252, -0.03740547224879265, -0.010268683545291424, -0.09062480926513672, 0.06632676720619202, -0.12214488536119461, -0.12156336009502411, -0.06068098172545433, 0.04381022974848747, 0.02318098209798336, -0.029297634959220886, -0.07807982712984085, -0.012405557557940483, -0.03458071127533913, -0.1022728979587555, -0.021300390362739563, 0.12981000542640686, -0.014186768792569637, 0.007861757650971413, 0.14738869667053223, -0.039716873317956924, 0.03398987278342247, 0.08772310614585876, -0.02737562544643879, 0.03054392896592617, -0.021817859262228012, -0.07060252875089645, -0.05266758054494858, 0.01709568127989769, 0.011377456597983837, 0.04087649658322334, -0.036464523524045944, -0.003554688300937414, -0.07383003830909729, -0.018397845327854156, 0.011544892564415932, -0.031050944700837135, -0.03964638337492943, -0.126711905002594, 0.04576169326901436, -0.03358848765492439, -0.09301840513944626, 0.10757072269916534, -0.018786277621984482, 0.04686656966805458, 0.012578180991113186, -0.021990492939949036, 0.06067020073533058, -0.05919646844267845, 0.04274335131049156, -0.07590397447347641, -6.384590989227945e-08, -0.030690835788846016, -0.028949325904250145, 0.00856297742575407, -0.019316187128424644, 0.034759677946567535, -0.16617973148822784, -0.023172637447714806, -0.006677104625850916, 0.037443775683641434, 0.032151125371456146, 0.002606916707009077, 0.0652524083852768, 0.014735627919435501, -0.09133752435445786, 0.0037452352698892355, 0.06454160809516907, -0.0668238028883934, 0.040770720690488815, -0.02574765682220459, 0.021087240427732468, 0.022267431020736694, -0.06495445966720581, 0.013158783316612244, -0.05199744552373886, -0.01786714419722557, 0.01855033077299595, -0.01123854611068964, 0.003821887308731675, 0.040517572313547134, 0.07130033522844315, -0.01608375646173954, 0.06361308693885803, 0.07083382457494736, 0.004367982968688011, -0.08132542669773102, -0.05275870859622955, 0.07407833635807037, 0.015528649091720581, 0.0688154548406601, -0.031153876334428787, -0.006720120552927256, -0.10037482529878616, 0.04151533171534538, 0.03749588876962662, -0.01957716792821884, 0.0034151538275182247, -0.06365732103586197, 0.02413984201848507, 0.06194670498371124, -0.028298310935497284, 0.07940936833620071, -0.03711883723735809, 0.052962809801101685, 0.08735568076372147, -0.044378478080034256, 0.0870845839381218, 0.041511110961437225, -0.019493643194437027, -0.0035007083788514137, 0.09980585426092148, -0.03640240430831909, -0.02915661223232746, 0.035331930965185165, -0.03695490583777428], '_distance': 1.079972743988037}, page_content='SBI General Insurance Company Limited                                                                                           \\n \\n \\nSBI General Insurance Company Limited Health Insurance Policy - Retail                      UIN: SBIHLIP21331V032021                   Page 10 of 45  \\nperiods and coverage of Pre-existing  Diseases . Coverage is not available for the period for which no premium is \\nreceived.  \\n \\n“Hospital ”: means any institution established for in - patient care and day care treatment of illness and / or injuries \\nand which has been registered as a Hospital  with the local authorities, under the Clinical Establishments (Registration \\nand Regulation) Act, 2010 or under the enactments specified under the Schedule of Section 56(1) of the said Act OR \\ncomplies  with all minimum criteria as under:  \\na. has qualified nursing staff under its employment round the clock;  \\nb. has at least 10 in -patient beds, in towns having populat ion of less than 10,00,000 and at least 15 inpatient \\nbeds in all other places;  \\nc. has qualified Medical Practitioner  (s) in charge round the clock;  \\nd. has a fully equipped operation theatre of its own where surgical procedures are carried out  \\ne. maintains daily rec ords of patients and make s these accessible to the  insurance company’s  authorized \\npersonnel.  \\n \\n“Hospitalisation ” means admission in a Hospital for a minimum period of 24 In Patient Care consecutive ‘In-patient \\nCare’ hours except for specified procedures/ treatments, where such admission could be for a period of less than 24 \\nconsecutive hours.  \\n \\n1. Illness  \\nIllness means a sickness or a disease or pathological condition leading to the impairment of normal \\nphysiological function which manifests itself during the Policy Period and requires medical treatment.  \\na. Acute Condition - Acute condition is a disease, illness or injury that is likely to respond quickly to \\ntreatment which aims to return the person to his or her state of health immediately before suffering \\nthe disease/illness/injury which leads to full recovery.  \\nb.  Chronic condition - A chronic condition is defined as a disease, illness, or injury that has one or more \\nof the following characteristics: —  \\n1. it needs ongoing or long -term monitoring through consultations, examinations, check -ups, \\nand / or tests — \\n2. it needs o ngoing or long -term control or relief of symptoms —  \\n3. it requires your rehabilitation or for you to be specially trained to cope with it — \\n4. it continues indefinitely — \\n5. it recurs or is likely to recur  \\n \\n \\n\"Injury \" means accidental physical bodily harm excluding il lness or disease solely and directly caused by external, \\nviolent and visible means which is verified and certified by a Medical Practitioner . \\n \\n“Insured ” means You/Your/Self/the person named in the Schedule , who is a citizen and resident of  India and for \\nwhom the insurance is proposed and appropriate premium paid.  \\n \\n“Insured Person” means the person named in the  Schedule / who is a resident of India and for whom the insurance is \\nproposed and appropriate premium paid. This includes Insured Person’s family .'), Document(metadata={}, page_content='The maximum length of stay allowed in Indian hospitals can vary depending on the specific hospital and the medical condition of the patient. There is no standard nationwide limit set by the government. It is recommended to check with the specific hospital or healthcare provider for their policies on length of stay.')]\n"
     ]
    }
   ],
   "source": [
    "op = app.invoke({\"keys\": {\"question\": \"How long can I stay in the hospital, maximum?\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dict(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_op=x[\"keys\"][\"generation\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The maximum length of stay allowed in Indian hospitals can vary depending on the specific hospital and the medical condition of the patient. There is no standard nationwide limit set by the government. It is recommended to check with the specific hospital or healthcare provider for their policies on length of stay. \\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
